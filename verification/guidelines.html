<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
<head>
  <meta content="text/html; charset=ISO-8859-1"
 http-equiv="content-type">
  <title>Aggregating verification scores</title>
</head>
<body>
<h3>Guidelines for computing aggregate statistics</h3>
<p>Real-time
verification systems often produce daily verification statistics from
the spatial comparisons of forecasts and observations, and store these
statistics in files. To get aggregate statistics for a period of many
days it is
tempting to simply average all of the daily verification statistics.
Note that
in general this does not give the same statistics as those that would
be
obtained by pooling the samples over many days. For the linear scores
such as
mean error, the same result is obtained, but for non-linear scores (for
example, anything involving a ratio) the results can be quite
different. </p>
<p>For example,
imagine a 30-day time series of the frequency bias score, and suppose
one day had an extremely high bias of 10 because the forecast predicted
an area
with rain but almost none was observed. If the forecast rain area was
20%
every day and this forecast was exactly correct on all of the other 29
days
(i.e., bias=1), the daily mean frequency bias would be 1.30, while the
frequency bias computed by pooling all of the days is only 1.03. These
two values
would lead to quite different conclusions regarding the quality of the
forecast.
</p>
<p>The
verification statistics for pooled samples are preferable to averaged
statistics because they are more robust. In most cases they can be
computed
from the statistics for daily forecasts if care is taken. (Note: we
talk about "daily" forecasts and statistics but these guidelines apply
to aggregating verification results from multiple forecasts on any
scale.)
The guidelines below
describe how
to correctly use the daily statistics to
obtain aggregate multi-day
statistics.
An assumption is made that each forecast contains the same number of
samples, <i>N</i> (number of gridpoints or stations).
</p>
<p><i>For pooled <a
 href="../index.php#Methods_for_dichotomous_forecasts">categorical
scores</a> computed from the
<a href="../index.php#Contingency_table">2x2
contingency table</a>: </i>
</p>
<p>&nbsp;&nbsp;&nbsp; First create
an aggregate contingency table of hits, misses, false alarms, and
correction
rejections by summing their daily values, then compute the categorical
scores as usual.
</p>
<p><i>For linear scores (<a href="../index.php#meanerror">mean
error</a>, <a href="../index.php#MAE">mean absolute error MAE</a>,
<a href="../index.php#MSE">mean squared error MSE</a>, <a
 href="../index.php#LEPS">linear error in probability space
LEPS</a>):</i>
</p>
<p>&nbsp;&nbsp;&nbsp; The average of the daily statistics is the same
as the statistics
computed from the
pooled values.
</p>
<p><i>For non-linear scores:</i>
</p>
<p>&nbsp;&nbsp;&nbsp; The key is
to transform the score into one for which it is valid to average the
daily values. The mean value is then transformed back into the original
form
of the score.
</p>
<p style="margin-left: 40px;"><a href="../index.php#RMS"><i>Root
mean squared error RMSE</i></a>:
First
square the daily values to obtain the <i>MSE</i>. Average the
squared values, then
take the square root of the mean value.
</p>
<p style="margin-left: 40px;"><a href="../index.php#RMSF"><i>Root
mean squared factor RMSF</i></a>:
Take the
logarithm of the daily values and square the result, then average these
values. Transform back to <i>RMSF</i> by taking the
square root and then the exponential.
</p>
<p style="margin-left: 40px;"><i>Variance s<sup>2</sup></i>: The
variance
can also be expressed as <img alt="Equation for sample variance"
 src="sf2eqn.gif" style="width: 182px; height: 46px;" align="middle">.
To compute the
pooled variance from the
daily variances,
subtract the second term (computed from the daily <img alt="Fbar"
 src="Fbar.gif" style="width: 15px; height: 19px;" align="middle">)
from&nbsp;<img alt="variance" src="sf2.gif"
 style="width: 19px; height: 21px;" align="middle"> to get
the
daily value of the first term. Average the daily values of the first
term, and use the average of the daily&nbsp;<img
 style="width: 15px; height: 19px;" src="Fbar.gif" alt="Fbar"
 align="middle"> values to compute
the second term. Recombine to get the pooled variance.
</p>
<p style="margin-left: 40px;"><i>Standard deviation s</i>: Square the
daily values of <i>s</i> to get daily variances. Compute
the pooled variance as above, then take the square root to get the
pooled
standard deviation.
</p>
<p style="margin-left: 40px;"><a href="../index.php#corr"><i>Correlation
coefficient r</i></a>:
Multiply
the daily correlations by the daily <font size="-1"><i
 style="font-family: helvetica,arial,sans-serif;">s<sub>F</sub></i></font>
x <font size="-1"><i style="font-family: helvetica,arial,sans-serif;">s<sub>O</sub></i></font>
to get the covariance, <font size="-1"><i
 style="font-family: helvetica,arial,sans-serif;">s<sub>FO</sub></i></font>.
The covariance
can be expressed as <img alt="covariance equation" src="sfo.gif"
 style="width: 212px; height: 43px;" align="middle">.
Follow the steps given for <font size="-1"><i
 style="font-family: helvetica,arial,sans-serif;">s<sup>2</sup></i></font>
above to get
a pooled covariance. Divide by the
product of the pooled standard deviations to get the pooled
correlation.
</p>
<p style="margin-left: 40px;"><i><a
 href="../index.php#Skill_score">Skill scores</a></i>: Use
the pooled
values of <i>MAE</i>
or <i>MSE</i> to compute the skill scores.
</p>
<p><br>
<a href="../index.php#Pooling_vs_stratifying_results">Back
to Forecast Verification - Issues, Methods and FAQ</a>
</p>
</body>
</html>
